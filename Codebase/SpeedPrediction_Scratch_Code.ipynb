{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Code from Primary NN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### segment_signal method with time tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for vectorized input WITHOUT SQL pre-processing\n",
    "    # ACTIVELY WORKING ON THIS METHOD FOR SPEED OPTIMIZATION (RIGHT NOW IT TAKES TOO LONG)\n",
    "def segment_signal(data_inputs, data_full, input_window_size = input_window_size):\n",
    "    TIME0 = time.time()\n",
    "    if  model_architecture == 'FCN':\n",
    "        segments = np.empty((0,input_window_size*num_channels + num_anthropometrics))\n",
    "    elif model_architecture == 'CNN':\n",
    "        segments = np.empty((0, input_window_size, num_channels + num_anthropometrics))\n",
    "    labels = np.empty((0))\n",
    "    \n",
    "    TIME1 = time.time()\n",
    "    TIME_INIT = TIME1 - TIME0\n",
    "    time_tracker_full_loop = [0]\n",
    "    time_tracker_cols = [0]\n",
    "    time_tracker_segment_stack = [0]\n",
    "    time_tracker_label_stack = [0]\n",
    "    entered_stracking = [0]\n",
    "    count = 0\n",
    "    \n",
    "    for (start, end) in windows(data_full['timestamp'], input_window_size):\n",
    "        \n",
    "        time_tracker_full_loop_start = time.time()\n",
    "        #time_range_tracker = np.hstack([time_range_tracker, (time_tracker_full_loop[count+1] - time_tracker_full_loop[count]) ]) #count+\n",
    "        count += 1\n",
    "        time_tracker_cols_start = time.time()\n",
    "        \n",
    "        a = data_inputs[\"bounce\"][start:end]\n",
    "        b = data_inputs[\"braking\"][start:end]\n",
    "        c = data_inputs[\"cadence\"][start:end]\n",
    "        d = data_inputs[\"ground_contact\"][start:end]\n",
    "        e = data_inputs[\"pelvic_drop\"][start:end]\n",
    "        f = data_inputs[\"pelvic_rotation\"][start:end]\n",
    "        g = data_inputs[\"pelvic_tilt\"][start:end]\n",
    "        if model_architecture == 'FCN':\n",
    "            aa = data_inputs[\"age\"][start]\n",
    "            bb = data_inputs[\"weight\"][start]\n",
    "            cc = data_inputs[\"height\"][start]\n",
    "            dd = data_inputs[\"gender\"][start] \n",
    "        elif model_architecture == 'CNN':\n",
    "            aa = data_inputs[\"age\"][start:end]\n",
    "            bb = data_inputs[\"weight\"][start:end]\n",
    "            cc = data_inputs[\"height\"][start:end]\n",
    "            dd = data_inputs[\"gender\"][start:end]         \n",
    "        \n",
    "        time_tracker_cols_end = time.time()\n",
    "        time_tracker_cols = np.hstack([time_tracker_cols, time_tracker_cols_end - time_tracker_cols_start])\n",
    "        time_tracker_segment_stack_start = time.time()\n",
    "        \n",
    "        if(end < data_full.shape[0] and len(data_full['timestamp'][start:end]) == input_window_size and data_full['activity_id'][start]==data_full['activity_id'][end]):\n",
    "            \n",
    "            entered_stracking = np.hstack([entered_stracking, count])\n",
    "            \n",
    "            if model_architecture == 'FCN':\n",
    "                segments_toadd = np.vstack([np.dstack([a,b,c,d,e,f,g])])\n",
    "                segments_toadd_reshape = segments_toadd.reshape(input_window_size * num_channels)\n",
    "                segments = np.vstack([segments,np.hstack([aa,bb,cc,dd,segments_toadd_reshape])])\n",
    "            elif model_architecture == 'CNN':\n",
    "                segments = np.vstack([segments,np.dstack([aa,bb,cc,dd,a,b,c,d,e,f,g])])\n",
    "            \n",
    "            time_tracker_segment_stack_end = time.time()\n",
    "            time_tracker_segment_stack = np.hstack([time_tracker_segment_stack, time_tracker_segment_stack_end - time_tracker_segment_stack_start])\n",
    "            time_tracker_label_stack_start = time.time()\n",
    "            \n",
    "            start_labeling = np.int(np.floor(start+(end-start)/2) - np.floor(label_window_size/2))\n",
    "            end_labeling = start_labeling + label_window_size\n",
    "            if speed_bucket_size == '0.1':\n",
    "                labels = np.append(labels,np.around(np.mean(data_full[\"gps_speed_true\"][start_labeling:end_labeling]),decimals=1)) # round to nearest decimal\n",
    "            elif speed_bucket_size == '0.5':\n",
    "                labels = np.append(labels,np.around(2*np.mean(data_full[\"gps_speed_true\"][start_labeling:end_labeling]),decimals=0)/2) # round to nearest half unit\n",
    "            elif speed_bucket_size == 'none_use_regression':\n",
    "                labels = np.append(labels,np.mean(data_full[\"gps_speed_true\"][start_labeling:end_labeling])) # no rounding, use regression\n",
    "            \n",
    "            time_tracker_segment_label_end = time.time()\n",
    "            time_tracker_label_stack = np.hstack([time_tracker_label_stack, time_tracker_segment_label_end - time_tracker_label_stack_start])\n",
    "            \n",
    "        else:\n",
    "            entered_stracking = np.hstack([entered_stracking, 0])\n",
    "        time_tracker_full_loop_end = time.time()\n",
    "        time_tracker_full_loop = np.hstack([time_tracker_full_loop, time_tracker_full_loop_end - time_tracker_full_loop_start])\n",
    "        \n",
    "    TIME2 = time.time()\n",
    "    TIME_LOOP = TIME2 - TIME1\n",
    "    print(TIME_INIT)\n",
    "    print(TIME_LOOP)\n",
    "    print(time_tracker_full_loop[0:1000])\n",
    "    print(time_tracker_full_loop[10000:11000])\n",
    "    print(time_tracker_cols[0:1000])\n",
    "    print(time_tracker_cols[10000:11000])\n",
    "    print(time_tracker_segment_stack[0:1000])\n",
    "    print(time_tracker_segment_stack[10000:11000])\n",
    "    print(time_tracker_label_stack[0:1000])\n",
    "    print(time_tracker_label_stack[10000:11000])\n",
    "    \n",
    "    print(entered_stracking)\n",
    "    return segments, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugger code for normalizing input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging Helper Code\n",
    "\n",
    "# #dataset = read_data(myFileLocation)\n",
    "# dataset_full = dataset\n",
    "# print(dataset[1:4])\n",
    "# print(dataset_full[1:4])\n",
    "# #dataset['gender':'pelvic_tilt_lag_0'] = (dataset - dataset.mean())/dataset.std()\n",
    "# dataset_inputs = dataset.loc[:, 'gender':'pelvic_tilt_lag_0'] # normalize all columns from gender to pelvic_tilt_lag_0\n",
    "# dataset_inputs_normalized = (dataset_inputs - dataset_inputs.mean())/dataset_inputs.std()\n",
    "# dataset_full.drop([\"gender\":\"pelvic_tilt_lag_0\"])\n",
    "# dataset_full = [dataset_full, dataset_inputs_normalized]\n",
    "# print(dataset[1:4])\n",
    "# print(dataset_full[1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debuger code for saving segment and labels as NP arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging helper code\n",
    "\n",
    "#     if data_input_table_structure == 'Raw_Timeseries':\n",
    "#         segments, labels = segment_signal(dataset_inputs_normalized, dataset)\n",
    "#     elif data_input_table_structure == 'Vectorized_By_Row':\n",
    "#         segments, labels = segment_signal_FCN_vector(dataset_inputs_normalized, dataset)\n",
    "\n",
    "#     if speed_bucket_size != 'none_use_regression': # if not using regression, convert to one-hot vector labels\n",
    "#          labels_to_number = np.unique(labels) # Caches \"labels_to_number\" in order to use in rmse calculation for classification\n",
    "#          labels = np.asarray(pd.get_dummies(labels), dtype = np.int8) # one-hot labels to classify nearest bucket\n",
    "#          num_buckets_total = len(labels[1]) # total number of classification buckets that exist in the dataset (here, classification bucket == classification class)\n",
    "            \n",
    "\n",
    "            \n",
    "# segments2 = np.load('../Saved NP Arrays/TESTPICKLE2.npy', allow_pickle=True)\n",
    "# np.save('../Saved NP Arrays/TESTPICKLE2', segments, allow_pickle=True)\n",
    "# #save_pickle_obj(segments, 'TESTPICKLE')\n",
    "\n",
    "print(segments.shape[0])\n",
    "print(len(segments))\n",
    "#reshaped_segments = segments.reshape(len(segments), 1,input_num_timestamps, num_channels)\n",
    "\n",
    "print(segments[0,0,1:10])\n",
    "print(labels.shape)\n",
    "print(segments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables removed from code for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Variables for CNN model    # THIS IS SILLY. GET RID OF THESE TWO VARIABLES, ADD COMMENTS FOR EASE OF USE/READING INSTEAD\n",
    "if model_architecture == 'CNN':\n",
    "    num_rows_per_example = segments.shape[1] # same as input_window_size\n",
    "    num_cols_per_example = segments.shape[2] # same as total channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution accidentally 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.add(Conv2D(num_filters, (kernel_size,1),input_shape=(input_window_size, num_channels+num_anthropometrics,1),activation=activation_conv_layer))\n",
    "    model.add(MaxPooling2D(pool_size=(max_pool_kernel_size,1),padding='valid',strides=(2,1)))\n",
    "    model.add(Conv2D(num_filters//10, (kernel_size,1),activation=activation_conv_layer)) # add additional CNN layer"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
