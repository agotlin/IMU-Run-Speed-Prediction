{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lumo Run - Deep Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout \n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras import regularizers \n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "from IPython import embed\n",
    "import time\n",
    "from time import strftime, gmtime\n",
    "import socket\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "np.random.seed(7) # Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Setup\n",
    "\n",
    "num_channels = 7 # number of time-series channels of data (i.e. 7 kinematic features) #NOTE: Change to 6 by removing Pelvic Tilt (recommended by Lumo)\n",
    "num_anthropometrics = 4 # number of user anthropometric data elements\n",
    "input_window_size = 11 # number of timestamps used in the input for prediction (i.e. the input window)\n",
    "label_window_size = 5 # number of timestamps used to label the speed we will be predicting\n",
    "speed_bucket_size = '0.1' # how to round the data for classification task. Consider '0.5', '0.1', and 'none_use_regression'\n",
    "myFileLocation = 'C:/Users/adam/Documents/CS 230/Project/Lumo Data/TimeSeries_InputVector_100runs.csv'\n",
    "        # Other data files to potentially use:\n",
    "        # '../datasets/SAMPLE_TimeSeries_Longest1000Runs_wAnthro_MultiLabeledSpeed_20180523.csv'\n",
    "        # '../datasets/quarter-big.csv'\n",
    "        # '../datasets/TimeSeries_InputVector_15runs.csv'\n",
    "        # 'C:/Users/adam/Documents/CS 230/Project/TimeSeries_InputVector_100runs.csv'\n",
    "        \n",
    "# Fully Connected Architecture\n",
    "\n",
    "num_hidden_units_fc_layers = [256, 256, 256, 128, 128, 128]\n",
    "num_hidden_fc_layers = len(num_hidden_units_fc_layers)\n",
    "\n",
    "activations_fc_layers = ['relu', 'relu', 'relu', 'relu', 'relu', 'relu']\n",
    "activations_strategy = ''.join(str(num) + \"_\" for num in activations_fc_layers)\n",
    "\n",
    "dropout_rate_fc_layers = [1.0, 1.0, 1.0, 0.8, 0.8, 0.8]\n",
    "dropout_rates = ''.join(str(num) + \"_\" for num in dropout_rate_fc_layers)\n",
    "\n",
    "# Training strategy\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 2\n",
    "loss_function = 'categorical_crossentropy' # Other options (from keras defaults or custom) include: 'categorical_crossentropy' ,'mse', 'mae', 'class_mse', 'class_mae'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up Automatic Reporting and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the 3 most interesting evaluation metrics to report on in final plots\n",
    "\n",
    "accuracy_reporting_metric_1 = 'class_mae' # options: 'acc', 'class_percent_1buckRange', 'class_percent_2buckRange'\n",
    "dev_reporting_metric_1 = 'val_' + accuracy_reporting_metric_1\n",
    "accuracy_reporting_metric_2 = 'class_percent_2buckRange' # options: 'acc', 'class_percent_1buckRange', 'class_percent_2buckRange'\n",
    "dev_reporting_metric_2 = 'val_' + accuracy_reporting_metric_2\n",
    "accuracy_reporting_metric_3 = 'class_mse' # options: s'acc', 'class_percent_1buckRange', 'class_percent_2buckRange'\n",
    "dev_reporting_metric_3 = 'val_' + accuracy_reporting_metric_3\n",
    "\n",
    "plt.style.use('ggplot') # style of matlab plots to produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File naming conventions\n",
    "\n",
    "file_name = strftime(\"%Y%m%d_%H%M%S\", gmtime()) # user input for filename of saved model\n",
    "results_file_name = \"Default_Model_Results_Storage_Table_20180712\"\n",
    "plot_note = \"\"\n",
    "model_to_lod = \"\"\n",
    "\n",
    "customize_file_names = False\n",
    "if customize_file_names:\n",
    "    file_name = input(\"String to add to model filename (defaults to time stamp if nothing entered):\")  \n",
    "    results_file_name = input(\"Name of the results file, a table, to store the prediction results\") # name of results file\n",
    "    plot_note = input(\"Note you'd like to add in the legend of the primary learning curves plot:\") #user input to add note to plot\n",
    "    model_to_load = input(\"Enter the model name to load to initialize parameters - leave blank to start fresh\") #user input to load prev model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions for data processing and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    data = pd.read_csv(file_path,header = 0) # This uses the header row (row 0) as the column names\n",
    "    return data\n",
    "\n",
    "def windows(data, size): # define time windows to create each training example\n",
    "    start = 0\n",
    "    while start < data.count():\n",
    "        yield int(start), int(start + size)\n",
    "        start += 1 # other common options: (size / 2)\n",
    "\n",
    "def segment_signal_vector(data_inputs, data_full): # Used for vectorized input WITH SQL pre-processing\n",
    "    dataframe_input = data_inputs.loc[:, 'gender':'pelvic_tilt_lag_0'] # select all columns from gender to pelvic_tilt_lag_0\n",
    "    dataframe_labels = data_full.loc[:, 'gps_speed_lag_7':'gps_speed_lag_3'] # select all columns from gender to pelvic_tilt_lag_0\n",
    "    segments = dataframe_input.values\n",
    "    labels_before_avg = dataframe_labels.values\n",
    "    if speed_bucket_size == '0.1':\n",
    "        labels = np.around(np.mean(labels_before_avg, axis=1),decimals=1)\n",
    "    elif speed_bucket_size == '0.5':\n",
    "        labels = np.around(2*np.mean(labels_before_avg, axis=1),decimals=0)/2\n",
    "    elif speed_bucket_size == 'none_use_regression':\n",
    "        labels = np.mean(labels_before_avg, axis=1)\n",
    "    return segments, labels\n",
    "\n",
    "def segment_signal(data_inputs, data_full, input_window_size = input_window_size): # Used for vectorized input WITHOUT SQL pre-processing\n",
    "    segments = np.empty((0,input_window_size*num_channels + num_anthropometrics))\n",
    "    labels = np.empty((0))\n",
    "    for (start, end) in windows(data_inputs['timestamp'], input_window_size):\n",
    "        aa = data_inputs[\"age\"][start]\n",
    "        bb = data_inputs[\"weight\"][start]\n",
    "        cc = data_inputs[\"height\"][start]\n",
    "        dd = data_inputs[\"gender\"][start] \n",
    "        a = data_inputs[\"bounce\"][start:end]\n",
    "        b = data_inputs[\"braking\"][start:end]\n",
    "        c = data_inputs[\"cadence\"][start:end]\n",
    "        d = data_inputs[\"ground_contact\"][start:end]\n",
    "        e = data_inputs[\"pelvic_drop\"][start:end]\n",
    "        f = data_inputs[\"pelvic_rotation\"][start:end]\n",
    "        g = data_inputs[\"pelvic_tilt\"][start:end]\n",
    "        if(end < data_full.shape[0] and\n",
    "           len(data_full['timestamp'][start:end]) == input_window_size and data_full['activity_id'][start]==data_full['activity_id'][end]):\n",
    "            segments_toadd = np.vstack([np.dstack([a,b,c,d,e,f,g])])\n",
    "            segments_toadd_reshape = segments_toadd.reshape(input_window_size * num_channels)\n",
    "            segments = np.vstack([segments,np.hstack([aa,bb,cc,dd,segments_toadd_reshape])])\n",
    "            start_labeling = np.int(np.floor(start+(end-start)/2) - np.floor(label_window_size/2))\n",
    "            end_labeling = start_labeling + label_window_size\n",
    "            if speed_bucket_size == '0.1':\n",
    "                labels = np.append(labels,np.around(np.mean(data_full[\"gps_speed_true\"][start_labeling:end_labeling]),decimals=1)) # round to nearest decimal\n",
    "            elif speed_bucket_size == '0.5':\n",
    "                labels = np.append(labels,np.around(2*np.mean(data_full[\"gps_speed_true\"][start_labeling:end_labeling]),decimals=0)/2) # round to nearest half unit\n",
    "            elif speed_bucket_size == 'none_use_regression':\n",
    "                labels = np.append(labels,np.mean(data_full[\"gps_speed_true\"][start_labeling:end_labeling])) # no rounding, use regression\n",
    "    return segments, labels\n",
    "\n",
    "def load_results_file(results_file_name):\n",
    "    my_file = Path(\"../Model Performance Tables/\" + results_file_name + \".csv\")\n",
    "    if my_file.is_file():\n",
    "        print(\"Found results file\")\n",
    "        prev_results=pd.read_csv(my_file,header=0)\n",
    "        print(list(prev_results.columns.values))\n",
    "        return prev_results\n",
    "    else:\n",
    "        print(\"no results file found - creating file\")\n",
    "        a=[[\"FCN\",\n",
    "            file_name,\n",
    "            \"na\",\n",
    "            myFileLocation,\n",
    "            training_epochs,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            batch_size,\n",
    "            num_hidden_fc_layers,\n",
    "            activations_strategy,\n",
    "            dropout_rates,\n",
    "            learning_rate,\n",
    "            speed_bucket_size,\n",
    "            loss_function,\n",
    "            input_window_size,\n",
    "            label_window_size,\n",
    "            \"\",\n",
    "            \"\",\n",
    "            \"\"\n",
    "            ]]\n",
    "        \n",
    "        df=pd.DataFrame(a, columns=[\"model type\",\n",
    "                                    \"model filename\",\n",
    "                                    \"plot filename\",\n",
    "                                    \"data filename\",\n",
    "                                    \"epochs\",\n",
    "                                    \"runtime\",\n",
    "                                    \"dev accuracy 1\",\n",
    "                                    \"train accuracy 1\",\n",
    "                                    \"dev accuracy 2\",\n",
    "                                    \"train accuracy 2\",\n",
    "                                    \"dev accuracy 3\",\n",
    "                                    \"train accuracy 4\",\n",
    "                                    \"batch_size\",\n",
    "                                    \"num_hidden_fc_layers\",\n",
    "                                    \"activations_strategy\",\n",
    "                                    \"dropout_rates\",\n",
    "                                    \"learning_rate\",\n",
    "                                    \"speed_bucket_size\",\n",
    "                                    \"loss_function\",\n",
    "                                    \"input_window_size\",\n",
    "                                    \"label_window_size\",\n",
    "                                    \"evaluation_metric_1\",\n",
    "                                    \"evaluation_metric_2\",\n",
    "                                    \"evaluation_metric_3\",])\n",
    "        \n",
    "        df.to_csv(\"../Model Performance Tables/\" + results_file_name + \".csv\",index=False ) \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_data(myFileLocation)\n",
    "\n",
    "# For input WITHOUT SQL pre-processing\n",
    "#dataset_inputs = dataset.loc[:, 'gender':'pelvic_tilt'] # normalize all columns from gender to pelvic_tilt\n",
    "#dataset_inputs_normalized = (dataset_inputs - dataset_inputs.mean())/dataset_inputs.std()\n",
    "\n",
    "# For input WITH SQL pre-processing\n",
    "dataset_inputs = dataset.loc[:, 'gender':'pelvic_tilt_lag_0'] # normalize all columns from gender to pelvic_tilt_lag_0\n",
    "dataset_inputs_normalized = (dataset_inputs - dataset_inputs.mean())/dataset_inputs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dataset = read_data(myFileLocation)\n",
    "# dataset_full = dataset\n",
    "# print(dataset[1:4])\n",
    "# print(dataset_full[1:4])\n",
    "# #dataset['gender':'pelvic_tilt_lag_0'] = (dataset - dataset.mean())/dataset.std()\n",
    "# dataset_inputs = dataset.loc[:, 'gender':'pelvic_tilt_lag_0'] # normalize all columns from gender to pelvic_tilt_lag_0\n",
    "# dataset_inputs_normalized = (dataset_inputs - dataset_inputs.mean())/dataset_inputs.std()\n",
    "# dataset_full.drop([\"gender\":\"pelvic_tilt_lag_0\"])\n",
    "# dataset_full = [dataset_full, dataset_inputs_normalized]\n",
    "# print(dataset[1:4])\n",
    "# print(dataset_full[1:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data using Team1 CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without SQL pre-processing\n",
    "#segments, labels = segment_signal(dataset_inputs_normalized, dataset)\n",
    "\n",
    "# With SQL pre-processing\n",
    "segments, labels = segment_signal_vector(dataset_inputs_normalized, dataset)\n",
    "if speed_bucket_size != 'none_use_regression': # if not using regression, convert to one-hot vector labels\n",
    "     labels_to_number = np.unique(labels) # Caches \"labels_to_number\" in order to use in rmse calculation for classification\n",
    "     labels = np.asarray(pd.get_dummies(labels), dtype = np.int8) # one-hot labels to classify nearest bucket\n",
    "     num_buckets_total = len(labels[1]) # total number of classification buckets that exist in the dataset (here, classification bucket == classification class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle data into training and dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_split = np.random.rand(len(segments)) < 0.90\n",
    "X_train = segments[train_dev_split]\n",
    "y_train = labels[train_dev_split]\n",
    "X_test = segments[~train_dev_split]\n",
    "y_test = labels[~train_dev_split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement NN architecture in a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# First layer\n",
    "model.add(Dense(num_hidden_units_fc_layers[0], activation=activations_fc_layers[0], input_shape=(input_window_size*num_channels + num_anthropometrics,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(dropout_rate_fc_layers[0]))\n",
    "# Intermediate layers\n",
    "for L in range(1, num_hidden_fc_layers):\n",
    "    model.add(Dense(num_hidden_units_fc_layers[L], activation=activations_fc_layers[L]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate_fc_layers[0]))\n",
    "# Last hidden layer\n",
    "if speed_bucket_size != 'none_use_regression': # if classification, use softmax for last layer\n",
    "    model.add(Dense(num_buckets_total, activation='softmax'))\n",
    "else:                                          # if regression, use linear for last layer\n",
    "    model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define custom loss functions and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def class_mse(y_true, y_pred):\n",
    "    return K.mean(K.square(K.sum(y_pred * labels_to_number,axis=-1,keepdims=True) - K.sum(y_true * labels_to_number,axis=-1,keepdims=True)), axis=-1)\n",
    "    # Note: we cannot define RMSE directly in Keras since the loss function is defined for one training example at a time\n",
    "\n",
    "def class_mae(y_true, y_pred):\n",
    "    return K.mean(K.abs(K.sum(y_pred * labels_to_number,axis=-1,keepdims=True) - K.sum(y_true * labels_to_number,axis=-1,keepdims=True)), axis=-1)\n",
    "\n",
    "def class_mape(y_true, y_pred):\n",
    "    diff = K.abs((K.sum(y_true * labels_to_number,axis=-1,keepdims=True) - K.sum(y_pred * labels_to_number,axis=-1,keepdims=True)) / K.clip(K.abs(K.sum(y_true * labels_to_number,axis=-1,keepdims=True)),K.epsilon(),None))\n",
    "    return 100. * K.mean(diff, axis=-1)\n",
    "\n",
    "def class_percent_1buckLow(y_true, y_pred): # percent of times the prediction is 1 bucket below the true value\n",
    "    return K.cast(K.equal(K.cast(K.argmax(y_true, axis=-1), K.floatx()), K.cast(K.argmax(y_pred, axis=-1),K.floatx())+1.0), K.floatx())\n",
    "\n",
    "def class_percent_2buckLow(y_true, y_pred): # percent of times the prediction is 2 buckets below the true value\n",
    "    return K.cast(K.equal(K.cast(K.argmax(y_true, axis=-1), K.floatx()), K.cast(K.argmax(y_pred, axis=-1),K.floatx())+2.0), K.floatx())\n",
    "    \n",
    "def class_percent_1buckHigh(y_true, y_pred): # percent of times the prediction is 1 bucket above the true value\n",
    "    return K.cast(K.equal(K.cast(K.argmax(y_true, axis=-1), K.floatx()), K.cast(K.argmax(y_pred, axis=-1),K.floatx())-1.0), K.floatx())    \n",
    "\n",
    "def class_percent_2buckHigh(y_true, y_pred): # percent of times the prediction is 2 buckets above the true value\n",
    "    return K.cast(K.equal(K.cast(K.argmax(y_true, axis=-1), K.floatx()), K.cast(K.argmax(y_pred, axis=-1),K.floatx())-2.0), K.floatx())    \n",
    "\n",
    "def class_percent_1buckRange(y_true, y_pred): # percent of times the prediction is within 1 bucket of true value\n",
    "    return K.cast(K.equal(K.cast(K.argmax(y_true, axis=-1), K.floatx()), K.cast(K.argmax(y_pred, axis=-1),K.floatx())-1.0), K.floatx()) + \\\n",
    "    K.cast(K.equal(K.cast(K.argmax(y_true, axis=-1), K.floatx()), K.cast(K.argmax(y_pred, axis=-1),K.floatx())+1.0), K.floatx()) + \\\n",
    "    K.cast(K.equal(K.argmax(y_true, axis=-1),K.argmax(y_pred, axis=-1)),K.floatx())\n",
    "\n",
    "def class_percent_2buckRange(y_true, y_pred): # percent of times the prediction is within 2 buckets of true value\n",
    "    return K.cast(K.equal(K.argmax(y_true, axis=-1),K.argmax(y_pred, axis=-1)),K.floatx()) + \\\n",
    "    K.cast(K.equal(K.cast(K.argmax(y_true, axis=-1), K.floatx()), K.cast(K.argmax(y_pred, axis=-1),K.floatx())-1.0), K.floatx()) + \\\n",
    "    K.cast(K.equal(K.cast(K.argmax(y_true, axis=-1), K.floatx()), K.cast(K.argmax(y_pred, axis=-1),K.floatx())+1.0), K.floatx()) + \\\n",
    "    K.cast(K.equal(K.cast(K.argmax(y_true, axis=-1), K.floatx()), K.cast(K.argmax(y_pred, axis=-1),K.floatx())-2.0), K.floatx()) + \\\n",
    "    K.cast(K.equal(K.cast(K.argmax(y_true, axis=-1), K.floatx()), K.cast(K.argmax(y_pred, axis=-1),K.floatx())+2.0), K.floatx())    \n",
    "\n",
    "# For reference, from keras documentation: https://github.com/keras-team/keras/blob/master/keras/losses.py\n",
    "#def class_categorical_accuracy(y_true, y_pred):\n",
    "    #return K.cast(K.equal(K.argmax(y_true, axis=-1),K.argmax(y_pred, axis=-1)),K.floatx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if speed_bucket_size != 'none_use_regression': # if performing classification, use cross-entropy loss\n",
    "    model.compile(loss ='categorical_crossentropy', optimizer='adam', metrics=['accuracy',class_percent_1buckRange,class_percent_2buckRange, class_mae, class_mse]) # class_percent_1buckLow,class_percent_1buckHigh,class_percent_2buckLow, class_percent_2buckHigh,'class_mape'\n",
    "else:                                          # if performing regression, use mean squared error or mean absolute error\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=['mse','mae']) # options: 'mse','mae', 'mape'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size= batch_size, epochs=training_epochs, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "end_time=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save a plot of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform key results into a np arrary\n",
    "trainAccuracy_1 = np.squeeze(history.history[accuracy_reporting_metric_1])\n",
    "devAccuracy_1 = np.squeeze(history.history[dev_reporting_metric_1])\n",
    "trainAccuracy_2 = np.squeeze(history.history[accuracy_reporting_metric_2])\n",
    "devAccuracy_2 = np.squeeze(history.history[dev_reporting_metric_2])    \n",
    "trainAccuracy_3 = np.squeeze(history.history[accuracy_reporting_metric_3])\n",
    "devAccuracy_3 = np.squeeze(history.history[dev_reporting_metric_3])\n",
    "trainAccuracy_4 = np.squeeze(history.history['acc'])\n",
    "devAccuracy_4 = np.squeeze(history.history['val_acc'])\n",
    "epochs = np.squeeze(range(1,training_epochs + 1))\n",
    "\n",
    "# Save results to a .csv in the \"Learning Curve Results\"\n",
    "df_devAccuracy = pd.DataFrame(np.transpose(np.vstack([epochs,devAccuracy_1, devAccuracy_2, devAccuracy_3, devAccuracy_4])))\n",
    "filepath_acc = \"../Learning Curves/\" + str(file_name) +\"_AccuracyPerEpoch_Data\" + \".csv\"\n",
    "df_devAccuracy.to_csv(filepath_acc, header = [\"Epochs\", dev_reporting_metric_1, dev_reporting_metric_2, dev_reporting_metric_2, 'acc'], index=False)\n",
    "\n",
    "# Declare final values for results\n",
    "final_accuracy_1 = history.history[accuracy_reporting_metric_1][training_epochs - 1]\n",
    "final_accuracy_dev_1 = history.history[dev_reporting_metric_1][training_epochs - 1]\n",
    "final_accuracy_2 = history.history[accuracy_reporting_metric_2][training_epochs - 1]\n",
    "final_accuracy_dev_2 = history.history[dev_reporting_metric_2][training_epochs - 1]\n",
    "final_accuracy_3 = history.history[accuracy_reporting_metric_3][training_epochs - 1]\n",
    "final_accuracy_dev_3 = history.history[dev_reporting_metric_3][training_epochs - 1]\n",
    "final_accuracy_4 = history.history['acc'][training_epochs - 1]\n",
    "final_accuracy_dev_4 = history.history['val_acc'][training_epochs - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.legend import Legend\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "lines=[]\n",
    "\n",
    "lines += ax1.plot(trainAccuracy_4,'#0e128c', label='Train Accuracy 2', linewidth=1) #'#DAF7A6'\n",
    "lines += ax1.plot(devAccuracy_4,'#a3a4cc', label='Dev Accuracy 2', linewidth=1)# '#33FF00',\n",
    "lines += ax1.plot(trainAccuracy_1,'#FF5733', label='Train Accuracy 1', linewidth=1)\n",
    "lines += ax1.plot(devAccuracy_1,'#C70039', label='Dev Accuracy 1', linewidth=1)\n",
    "lines += ax1.plot(trainAccuracy_2,'#9C27B0', label='Train Accuracy 2', linewidth=1)\n",
    "lines += ax1.plot(devAccuracy_2,'#7986CB', label='Dev Accuracy 2', linewidth=1)\n",
    "plt.ylim([0.0, 1.0])  # Surpress this for non-classification tasks\n",
    "\n",
    "plt.ylabel('Train vs. Dev Accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.title(dev_reporting_metric_1 + \": \" + str(np.around(final_accuracy_dev_1,4)) + \"\\n\" + \\\n",
    "         dev_reporting_metric_2 + \": \" + str(np.around(final_accuracy_dev_2,4))) \n",
    "extra = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "plt.legend([extra,extra,extra,extra,extra,extra,extra,extra,extra,extra],(\n",
    "                                                \"loss: \" + loss_function,\n",
    "                                                \"learning rate: \" + str(learning_rate),\n",
    "                                                \"batch_size: \" + str(batch_size),\n",
    "                                                \"speed_bucket_size: \" + speed_bucket_size,\n",
    "                                                \"epochs: \"+str(training_epochs),\n",
    "                                                \"input_window_size: \" + str(input_window_size),\n",
    "                                                \"num_labels: \" + str(len(labels_to_number)),\n",
    "                                                \"evaluation metric 1:\"+accuracy_reporting_metric_1,\n",
    "                                                \"evaluation metric 2:\"+accuracy_reporting_metric_2,\n",
    "                                                \"evaluation metric 3:\"+accuracy_reporting_metric_3,\n",
    "                                                \"note:\" + plot_note),\n",
    "                                                bbox_to_anchor=(1.05, 1),\n",
    "                                                loc=2,\n",
    "                                                borderaxespad=0.)\n",
    "\n",
    "leg = Legend(ax1, lines[0:], ['Train ACC', 'Dev ACC','Train Eval 1','Dev Eval 2'],\n",
    "             loc='bestoutside', frameon=False)\n",
    "ax1.add_artist(leg);\n",
    "plt.savefig(\"../Learning Curves/\" + str(file_name) + \"_AccuracyPerEpoch_Image.png\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record results of a model in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_time = end_time-start_time\n",
    "time_per_epoch = model_time/training_epochs\n",
    "\n",
    "# Add the results of the most recent run to the results file for documentation\n",
    "a=[[\"FCN\",\n",
    "    file_name,\n",
    "    \"na\",\n",
    "    myFileLocation,\n",
    "    training_epochs,  \n",
    "    model_time,\n",
    "    final_accuracy_1,\n",
    "    final_accuracy_dev_1,\n",
    "    final_accuracy_2,\n",
    "    final_accuracy_dev_2,\n",
    "    final_accuracy_3,\n",
    "    final_accuracy_dev_3,\n",
    "    batch_size,\n",
    "    num_hidden_fc_layers,\n",
    "    activations_strategy,\n",
    "    dropout_rates,    \n",
    "    learning_rate,\n",
    "    speed_bucket_size,\n",
    "    loss_function,\n",
    "    input_window_size,\n",
    "    label_window_size,\n",
    "    accuracy_reporting_metric_1,\n",
    "    accuracy_reporting_metric_2,\n",
    "    accuracy_reporting_metric_3\n",
    "    ]]\n",
    "        \n",
    "df=pd.DataFrame(a, columns=[\"model type\",\n",
    "                            \"model filename\",\n",
    "                            \"plot filename\",\n",
    "                            \"data filename\",\n",
    "                            \"epochs\",\n",
    "                            \"runtime\",\n",
    "                            \"train accuracy 1\",\n",
    "                            \"dev accuracy 1\",\n",
    "                            \"train accuracy 2\",\n",
    "                            \"dev accuracy 2\",\n",
    "                            \"train accuracy 3\",\n",
    "                            \"dev accuracy 3\",\n",
    "                            \"batch_size\",\n",
    "                            \"num_hidden_fc_layers\",\n",
    "                            \"activations_strategy\",\n",
    "                            \"dropout_rates\",    \n",
    "                            \"learning_rate\",\n",
    "                            \"speed_bucket_size\",\n",
    "                            \"loss_function\",\n",
    "                            \"input_window_size\",\n",
    "                            \"label_window_size\",\n",
    "                            \"evaluation_metric_1\",\n",
    "                            \"evaluation_metric_2\",\n",
    "                            \"evaluation_metric_3\"])\n",
    "\n",
    "past_results = load_results_file(results_file_name)\n",
    "past_results=pd.concat([past_results,df])\n",
    "print(past_results)\n",
    "past_results.to_csv(\"../Model Performance Tables/\" + results_file_name + \".csv\",index=False ) # FIX TO PUT THE COLUMNS NOT ALPHABETICAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Confusion Matrix and Regression Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_argmax = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_true = y_test\n",
    "y_true_argmax = np.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.scatter(y_true_argmax, y_pred_argmax, s=3, alpha=0.3)\n",
    "plt.scatter(y_true_argmax, y_true_argmax, s=3, alpha=1)\n",
    "#plt.scatter(y_true, y_pred, s=3, alpha=0.3) # For regression\n",
    "plt.xlim([0,50])\n",
    "plt.ylim([0,50])\n",
    "plt.xlabel('Y_True')\n",
    "plt.ylabel('Y_Prediction')\n",
    "plt.savefig(\"../Confusion Matrices/\" + str(file_name) + \"_ConfusionMatrix_Image.png\")\n",
    "plt.show()\n",
    "\n",
    "# Record data in a .csv\n",
    "y_trueVy_pred = np.vstack([y_true_argmax,y_pred_argmax])\n",
    "df_y_trueVy_pred = pd.DataFrame(np.transpose(y_trueVy_pred))\n",
    "filepath_predictions = \"../Model Final Predictions/\" + str(file_name) + \"_Predictions\" + \".csv\"\n",
    "df_y_trueVy_pred.to_csv(filepath_predictions, header = [\"y_true_argmax\", \"y_pred_argmax\"], index=False)\n",
    "\n",
    "# Create and save a confusion matrix\n",
    "cm = confusion_matrix(y_true_argmax, y_pred_argmax)\n",
    "df_cm = pd.DataFrame (cm)\n",
    "filepath_cm = \"../Confusion Matrices/\" + str(file_name) + \"_ConfusionMatrix_Data.xlsx\"\n",
    "df_cm.to_excel(filepath_cm, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
