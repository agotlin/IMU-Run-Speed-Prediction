{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReadMe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script take a data array X and a label vector Y and fits linear regression parameters theta using scikit package\n",
    "\n",
    "Shapes:\n",
    "X = (m, n) where m is number of training examples and n is number of features\n",
    "Y = m\n",
    "theta = n + 1 (+1 for bias term)\n",
    "\n",
    "Sections:\n",
    "\n",
    "1) (OPTIONAL) Create a dummy data vector and label vector\n",
    "\n",
    "2) Implement linear regression using stochastic gradient descent to learn parameters theta\n",
    "\n",
    "3) Report performance of linear regression compared to zero rule algorithm (i.e. guess the mean output always)\n",
    "\n",
    "Citations:\n",
    "\n",
    "https://machinelearningmastery.com/implement-linear-regression-stochastic-gradient-descent-scratch-python/\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: (OPTIONAL) Create dummy data vectors and label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(7)\n",
    "X, Y = make_regression(n_samples=1000, n_features=100000, noise=0.2, n_informative = 1000)\n",
    "Y = np.rint(np.interp(Y, (Y.min(), Y.max()), (0, 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Linear Regression with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8 # ratio of training examples to put into train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data to have 0 mean and unit variance (the default)\n",
    "X_normalized = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_split = np.random.rand(len(Y)) < train_split # split data into 90% train, 10% dev, based on lenghto of labels\n",
    "X_train = X_normalized[train_dev_split]\n",
    "X_test = X_normalized[~train_dev_split]\n",
    "Y_train = Y[train_dev_split]\n",
    "Y_test = Y[~train_dev_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.shape); print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object using scitkit\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "Y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Report Results and Compare to Zero-Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate RMSE and Variance (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root mean squared error of Linear Regression: %.2f\"\n",
    "      % sqrt(mean_squared_error(Y_test, Y_pred)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate RMSE and Variance (Zero-Rule for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_0rule = np.full_like(Y_test, np.mean(Y_train))  \n",
    "\n",
    "# The mean squared error\n",
    "print(\"Root mean squared error of Zero Rule: %.2f\"\n",
    "      % sqrt(mean_squared_error(Y_test, Y_pred_0rule)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(Y_test, Y_pred_0rule))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Linear Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs. true\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y_test, Y_pred, edgecolors=(0, 0, 0))\n",
    "ax.plot([Y_test.min(), Y_test.max()], [Y_pred.min(), Y_pred.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('GDI True')\n",
    "ax.set_ylabel('GDI Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.random.rand(100,1000000)\n",
    "# Y = np.random.randint(0,101,1000)\n",
    "# generate regression dataset\n",
    "\n",
    "#print(X); print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min and max values for each feature column in dataset\n",
    "# def dataset_minmax(dataset):\n",
    "#     minmax = list()\n",
    "#     for i in range(len(dataset[0])):\n",
    "#         col_values = [row[i] for row in dataset]\n",
    "#         value_min = min(col_values)\n",
    "#         value_max = max(col_values)\n",
    "#         minmax.append([value_min, value_max])\n",
    "#     return minmax\n",
    " \n",
    "# # Rescale dataset features to the range 0-1\n",
    "# def normalize_dataset(dataset, minmax):\n",
    "#     dataset_normalized = (dataset - dataset.mean())/dataset.std()\n",
    "#     return dataset_normalized\n",
    "\n",
    "# minmax = dataset_minmax(X)\n",
    "# X_normalized = normalize_dataset(X, minmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
